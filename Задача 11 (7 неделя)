# В этой задаче достаточно обернуть в функцию то, что делает предыдущая и вызвать подсчет числа внутренних ссылок
# для двух статей:
# https://raw.githubusercontent.com/zevs57/zevs57/main/task_7_4_2%2528Moscow%2529.html
# и https://raw.githubusercontent.com/zevs57/zevs57/main/task_7_4_2%2528New-York%2529.html
#
# В качестве ответа на задачу введите два числа через пробел.

from urllib.request import urlopen
from bs4 import BeautifulSoup


def getlinks(url):
    response = urlopen(url)
    html = response.read().decode("utf-8")
    soup = BeautifulSoup(html, 'html.parser')
    links = []

    for link in soup.find_all("a"):
        if link.has_attr("href"):
            s = link.get("href")
            if not s.startswith("http://") and not s.startswith("https://") and not s.startswith(
                    "#") and not "//" in s and ":" not in s:
                links.append(link.get("href"))
    print(len(links))


getlinks("https://raw.githubusercontent.com/zevs57/zevs57/main/task_7_4_2%2528Moscow%2529.html")
getlinks("https://raw.githubusercontent.com/zevs57/zevs57/main/task_7_4_2%2528New-York%2529.html")
