# Мы сохранили статью с википедии, она доступна по ссылке
# https://raw.githubusercontent.com/zevs57/zevs57/163b5efc8d3e401ebfad019bff83a051d0d149ff/task_7_3_1.html
#
# Вам необходимо обработать ее с помощью BeautifulSoup и вывести все внешние ссылки,
# которые есть на этой странице, в том порядке как они встречались по одной в строке.
#
# Под ссылкой понимается содержимое аттрибута href тега a. Ссылка называется внешней,
# если она ведет на другой сайт (т.е. начинается с http:// или https://).
#
# Вам могут быть полезны методы find_all для супа (он позволяет найти все теги на странице),
# метод has_attr для тега (проверяет есть ли такой атрибут у тега) и доступ к атрибуту тега по аналогии со словарем.

from urllib.request import urlopen
from bs4 import BeautifulSoup

response = urlopen("https://raw.githubusercontent.com/zevs57/zevs57/163b5efc8d3e401ebfad019bff83a051d0d149ff"
                   "/task_7_3_1.html") 
html = response.read().decode("utf-8")
soup = BeautifulSoup(html, 'html.parser')

for link in soup.find_all("a"):
    if link.has_attr("href"):
        s = link.get("href")
        if s.startswith("http://") or s.startswith("https://"):
            print(link.get("href"))
